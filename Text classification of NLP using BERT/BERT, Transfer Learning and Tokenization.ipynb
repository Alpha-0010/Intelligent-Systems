{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a04a2999-ab2e-44c9-8b2d-145a38645296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT stands for Bidirectional Encoder Representations for Transformers. Google uses BERT and the overview that we see in google when we ask a question\n",
    "# is from BERT. It is a direct question answering application of Transformers , BERT in this case.\n",
    "\n",
    "# BERT was trained on Masked Language Model (MLM) and Next Sentence Prediction (NSP).\n",
    "# We don't need labeled data with BERT we can train on raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becc460b-f8b2-4378-8b26-174a4a4b2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning is made up of 2 components :- Pretraining and Fine-tuning.\n",
    "\n",
    "# We typically have 3 stages in Model training :-\n",
    "# 1) Model architecture with random weights. (Non knowledge of language)\n",
    "# 2) Pretrained model. (Very good understanding of knowledge) \n",
    "# 3) Fine-tuned model. (With BERT fine-tuning can be in form of Text classification, Named entity recognition, Question Answering)\n",
    "\n",
    "# BERT already gives us the pretrained model, we just need to fine-tune it to our use-case.\n",
    "# The fine tuning steps involves training the model with labelled data.\n",
    "\n",
    "# Transfer learning is better because it only requires us to fine tune the model, so it is faster, requires less data to fine-tune and gives excellent\n",
    "# results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f794e9-5bfd-4061-89e1-3499b17ecda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransformer Architecture :-\\n\\nA transformer is made up of an encoder and a decoder. We fed an english language into an encoder and the transformer can act as a translater\\nand we will get the German translation from the decoder.\\n\\n1. Ecoder-Descoder models can be used for Generative tasks that require input like translation or summarization. Eg: BART, T5\\n2. Encoder only model are used when we require understanding of the input like sentence classification and Named entity recognition. Eg: Bert\\n3. Decoder only models are used when we need Generative tasks. Eg: GPT\\n\\nBERT cannot generate texts as it doesnot have decoder like translation or text summarization.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transformer Architecture :-\n",
    "\n",
    "A transformer is made up of an encoder and a decoder. We fed an english language into an encoder and the transformer can act as a translater\n",
    "and we will get the German translation from the decoder.\n",
    "\n",
    "1. Ecoder-Descoder models can be used for Generative tasks that require input like translation or summarization. Eg: BART, T5\n",
    "2. Encoder only model are used when we require understanding of the input like sentence classification and Named entity recognition. Eg: Bert\n",
    "3. Decoder only models are used when we need Generative tasks. Eg: GPT\n",
    "\n",
    "BERT cannot generate texts as it doesnot have decoder like translation or text summarization.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dbaf98c-7a9b-43a5-b5a1-d2f39e87d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy tokenizers?\\nWords are split into sub-words and sub-words are mapped to numerical-ids and tokenizers convert text inputs to numerical data.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Why tokenizers?\n",
    "Words are split into sub-words and sub-words are mapped to numerical-ids and tokenizers convert text inputs to numerical data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5795e769-e9e3-4dec-8bbe-019b1c550bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers[sentencepiece] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ef03db5-eb27-4107-8aa7-d47ff0f848ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d2c4df951c4f10bef94c8dc626a8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560a22b43eff4572b10bca9502b12dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3028291725354b64805894949c384380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a194b43be9234c2fa3d9e948ca34ed95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66dff67a-17df-4545-8fb5-1c8a153a38d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size is 30522\n"
     ]
    }
   ],
   "source": [
    "# print(tokenizer.vocab)\n",
    "print(f'The vocabulary size is {len(tokenizer.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd66d8e3-6078-44f6-83f4-62c3ffe59f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like NLP\n",
      "['i', 'like', 'nl', '##p']\n",
      "[101, 1045, 2066, 17953, 2361, 102]\n",
      "[CLS] i like nlp [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I like NLP'\n",
    "print(sentence)\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)\n",
    "ids = tokenizer.encode(sentence)\n",
    "print(ids)\n",
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610ee008-2a87-48e4-a2d9-eaa966c4f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] -> 101\n",
      "[SEP] -> 102\n"
     ]
    }
   ],
   "source": [
    "print(f'{tokenizer.cls_token} -> {tokenizer.cls_token_id}')\n",
    "print(f'{tokenizer.sep_token} -> {tokenizer.sep_token_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b869a03a-9fc8-4fa7-9776-e9a80a7658db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ðŸ˜€' in tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35300797-763d-4231-8644-41539e708f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', '[UNK]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'I like NLPðŸ˜€'\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eefc92b3-9742-4d11-bfd1-ae620c5d64ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1045,  2066, 17953,  2361,  1012,   102,  2054,  2055,  2017,\n",
       "          1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sentence = 'I like NLP.'\n",
    "second_sentence = 'What about you?'\n",
    "input = tokenizer(first_sentence, second_sentence, return_tensors='pt')\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd2b88e5-043f-47e9-8701-7d0b012f4e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1045,  2066, 17953,  2361,  1012,   102,  2054,  2055,  2017,\n",
       "          1029,   102]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6cab545-4951-4c90-9b43-ed64c9ef8f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['token_type_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62029a19-b25e-4100-9bac-e8af1c8e0c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d4a3376-8ee9-460c-9dd4-abe1f16fed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sentence = 'I like NLP.'\n",
    "second_sentence = 'What are your thoughts on the subject?'\n",
    "input = tokenizer([first_sentence, second_sentence], padding=True, return_tensors='pt')\n",
    "input['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ac23a-6327-4c5e-b690-ba747c137171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
